Project Report: UltraEdge Video Processing
1. Introduction
This project focuses on developing a video processing tool using OpenCV in Python, with the aim of analyzing video frames to detect edges, which is inspired by the UltraEdge technology used in cricket for detecting fine edges off the bat. The project processes video input to extract edge details using the Canny edge detection algorithm and displays both the original frame and the edges detected in real-time.

2. Objectives
The primary objective of this project is to:

Capture video input and process it frame by frame.
Convert the video frames to grayscale.
Apply the Canny edge detection algorithm to highlight the edges within each frame.
Display the processed edge-detected frames alongside the original frames.
Allow user interaction to terminate the video processing.
3. Project Components
a. Video Capture:

The video is captured using OpenCV's VideoCapture function, which reads frames from a video file ("ultraEdge.mp4").
b. Frame Processing:

Resizing: Each frame is resized to a fixed dimension of 690x590 pixels to ensure uniformity in processing and display.
Grayscale Conversion: The resized frame is converted to grayscale using cv2.cvtColor to simplify the image data and prepare it for edge detection.
Edge Detection: The Canny edge detection algorithm is applied to the grayscale frame to detect edges. The parameters used for this algorithm are 18 and 180 for the lower and upper thresholds, respectively.
c. Displaying the Output:

Edge Detection Output: The processed frame showing the detected edges is displayed using cv2.imshow.
Original Frame Output: The original frame (after resizing) is also displayed to allow comparison with the edge-detected version.
d. User Interaction:

The video processing loop continues until the user presses the 'c' key, which breaks the loop and stops the video.
e. Resource Management:

After the processing loop is exited, the video capture object is released using video.release() and all OpenCV windows are closed using cv2.destroyAllWindows() to free up resources.







Key Functions and Their Purpose:

cv2.VideoCapture("ultraEdge.mp4"): Opens the video file for frame-by-frame processing.
cv2.resize(frame, (690, 590)): Resizes the video frames to a consistent size.
cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY): Converts the frame to grayscale.
cv2.Canny(gray, 18, 180): Detects edges in the grayscale image using the Canny algorithm.
cv2.imshow(): Displays the processed frames in separate windows.
cv2.waitKey(25): Waits for 25 milliseconds before processing the next frame.
video.release(): Frees up the video capture resource.
cv2.destroyAllWindows(): Closes all display windows.
5. Challenges Faced
Parameter Tuning: Adjusting the Canny edge detection thresholds to get a clear and meaningful edge detection output was a key challenge. The values 18 and 180 were chosen after experimentation for optimal edge detection in the given video.

Real-Time Processing: Ensuring that the frame processing and display occurred in real-time was critical to achieving a smooth and responsive user experience.

6. Conclusion
This project successfully demonstrates the application of basic computer vision techniques using OpenCV for video processing. The ability to capture, process, and display video frames in real-time opens up opportunities for more advanced video analysis and processing tasks in the future, such as object detection, tracking, or even machine learning-based classification.

7. Future Work
Integration with Audio Processing: Since UltraEdge technology also involves audio detection, future work could involve integrating audio signal processing to create a more comprehensive simulation.
Advanced Edge Detection: Experimenting with other edge detection techniques or improving the current Canny algorithm by adaptive thresholding.
User Interface Enhancement: Developing a more user-friendly interface, possibly using GUI libraries like Tkinter or PyQt.
